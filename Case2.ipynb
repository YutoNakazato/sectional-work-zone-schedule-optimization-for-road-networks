{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ipynb file for Case 2 Sioux Falls road network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Preparation\n",
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import gurobipy as grb\n",
    "from itertools import product\n",
    "import itertools\n",
    "import numpy as np\n",
    "import TNTP\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding of supportive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base(decimal_number, base):\n",
    "    DIGITS = '0123456789abcdef'\n",
    "    remainder_stack = []\n",
    "\n",
    "    while decimal_number > 0:\n",
    "        remainder = decimal_number % base\n",
    "        remainder_stack.append(remainder)\n",
    "        decimal_number = decimal_number // base\n",
    "\n",
    "    new_digits = []\n",
    "    while remainder_stack:\n",
    "        new_digits.append(DIGITS[remainder_stack.pop()])\n",
    "\n",
    "    return ''.join(new_digits)\n",
    "def de_to_base(de,base,num):\n",
    "    de2=convert_to_base(de, base)\n",
    "    otpt=np.zeros(num, dtype=int)\n",
    "    i=-1\n",
    "    for x in de2:\n",
    "        otpt[i]=otpt[i]+int(de2[i])\n",
    "        i=i-1\n",
    "    return otpt\n",
    "\n",
    "def base_to_de(X,n):\n",
    "    out = 0\n",
    "    for i in range(len(X)):\n",
    "        out += int(X[-i-1])*(n**(i))\n",
    "    return out\n",
    "\n",
    "def list_to_tuple(_list):\n",
    "    t = ()\n",
    "    for e in _list:\n",
    "        if isinstance(e,list):\n",
    "            t += (list_to_tuple(e),)\n",
    "        else:\n",
    "            t += (e,)\n",
    "    return t\n",
    "\n",
    "def odmatrix(nodes,node_od,sizerate): \n",
    "    odmat=np.zeros(3,'int')\n",
    "    for i in nodes: \n",
    "        for j in nodes: \n",
    "            if node_od[i][j]>0: \n",
    "                odtmp=np.zeros(3,'int')\n",
    "                odtmp[0]=i \n",
    "                odtmp[1]=j \n",
    "                odtmp[2]=node_od[i][j]*sizerate\n",
    "                odmat=np.vstack([odmat,odtmp])\n",
    "    odmat=np.delete(odmat,0,0)\n",
    "    return odmat \n",
    "\n",
    "def makeod_dict(nodes,node_od,sizerate):\n",
    "    odpairdict=()\n",
    "    odarray=[]\n",
    "    for i in node_od:\n",
    "        for j in node_od[i]:\n",
    "            odpairdict=odpairdict+((i,j),)\n",
    "            odarray.append(node_od[i][j])\n",
    "    od_dict=dict(zip(odpairdict,odarray))\n",
    "    return od_dict\n",
    "\n",
    "def noise(prob):\n",
    "    return 1 if random.random() <= prob else 0\n",
    "\n",
    "def random_rep_id(linklength,repprob,seed=21,secnumperlink=1609/100):\n",
    "    random.seed(seed)\n",
    "    linksize=round(linklength*secnumperlink)\n",
    "    randomid_link=[]\n",
    "    for i in range(linksize):\n",
    "            randomid_link.append(noise(repprob))\n",
    "    return randomid_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load inputs for SiouxFalls network from tntp file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Lower level: Section-unit link-level Pareto frontier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net file:\t./SiouxFalls\\SiouxFalls_net.tntp\n",
      "trips file:\t./SiouxFalls\\SiouxFalls_trips.tntp\n"
     ]
    }
   ],
   "source": [
    "#Import inputs from tntp file\n",
    "root = '.' \n",
    "dir_name = 'SiouxFalls' \n",
    "\n",
    "#Maximum number of continuous work zones per day: M. \n",
    "maxmachinenum=20\n",
    "\n",
    "#User cost weight. \n",
    "ucrate=1\n",
    "\n",
    "#Work zone cost weight\n",
    "wcrate=1\n",
    "\n",
    "#Probability each section of the road network require repair\n",
    "repprob=0.2\n",
    "\n",
    "#Number of days in the plan\n",
    "timespan=365\n",
    "\n",
    "#Fixed work zone cost\n",
    "mcucost=500\n",
    "\n",
    "#Variable work zone cost\n",
    "wzucost=100\n",
    "\n",
    "#Traffic capacity ratio in the work zone\n",
    "Brate=0.5\n",
    "\n",
    "#Detour route cost\n",
    "dummy_cost=300\n",
    "\n",
    "#Ratio of the traffic demand to the original data\n",
    "odsize=0.8\n",
    "\n",
    "ntw = TNTP.Network(root, dir_name)\n",
    "links_dict = (ntw.links_bn)\n",
    "links_data_array = np.array(links_dict)\n",
    "\n",
    "node_od=ntw.trips\n",
    "nodes = np.sort(np.unique(links_data_array.flatten()))\n",
    "\n",
    "cost_data_array=ntw.fftt\n",
    "cost_dict=dict(zip(links_dict,cost_data_array))\n",
    "\n",
    "capacity_data = ntw.capacity\n",
    "capacity_dict=dict(zip(links_dict,capacity_data))\n",
    "od_dict=makeod_dict(nodes,node_od,odsize)\n",
    "odmat=odmatrix(nodes,node_od,odsize)\n",
    "links_data_tuple=links_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modification of type of the inputs\n",
    "\n",
    "links_data_array = np.array(links_data_tuple)\n",
    "\n",
    "nodes = np.sort(np.unique(links_data_array.flatten()))\n",
    "\n",
    "cost_dict=dict(zip(links_data_tuple,cost_data_array))\n",
    "\n",
    "capacity_dict=dict(zip(links_data_tuple,capacity_data))\n",
    "\n",
    "od_dict={(1,2):400*odsize,(1,3):800*odsize,(4,2):600*odsize,(4,3):200*odsize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculating optimal 1 day work zone schedule with constraints of maximum number of continuous work zones per day.\n",
    "def linkrepplans(repid,machinecost=1000, workzonecost=100,maxworkzonelength=10,maxmachinenum=100):\n",
    "    repplangrbm=()\n",
    "    with grb.Env(empty=True) as env:\n",
    "        env.setParam('OutputFlag', 0)\n",
    "        env.start()\n",
    "        with grb.Model(env=env) as repplangrbm:\n",
    "            linksize=len(repid)\n",
    "            link_machineid={}\n",
    "            if maxmachinenum>sum(repid):\n",
    "                maxmachinenum=sum(repid)\n",
    "            link_machineid=repplangrbm.addVars(linksize,vtype=grb.GRB.INTEGER,lb=0,ub=maxmachinenum)\n",
    "            workzone01={}\n",
    "\n",
    "            workzone01=repplangrbm.addVars(linksize,vtype=grb.GRB.BINARY)\n",
    "\n",
    "            repplangrbm.update()\n",
    "\n",
    "            machineidincrease=repplangrbm.addConstrs( link_machineid[i+1]>= link_machineid[i] for i in range(linksize-1))\n",
    "            machineworkzoneconst=repplangrbm.addConstrs((workzone01[i+1]-workzone01[i])*(link_machineid[i+1]-link_machineid[i]-0.5)>=0 for i in range(linksize-1))\n",
    "            workzonelengthconst=repplangrbm.addConstrs(repid[i+maxworkzonelength]*(link_machineid[i+maxworkzonelength]-link_machineid[i]-1)>=0   for i in range(linksize-maxworkzonelength))\n",
    "            workzone01const=repplangrbm.addConstrs( repid[i]<= workzone01[i] for i in range(linksize))\n",
    "            machine01const=repplangrbm.addConstrs( workzone01[i]<= link_machineid[i] for i in range(linksize))\n",
    "\n",
    "            repplangrbm.setObjective(grb.quicksum(workzone01[i] for i in range(linksize))*workzonecost,grb.GRB.MINIMIZE)\n",
    "            repplangrbm.update()\n",
    "            repplangrbm.optimize()\n",
    "            repplangrbm.status\n",
    "            \n",
    "            link_machineidopt=[]\n",
    "            workzonenum=0\n",
    "            try:\n",
    "                for i in range(linksize):\n",
    "                    link_machineidopt.append(link_machineid[i].X)\n",
    "                    workzonenum=workzonenum+workzone01[i].X\n",
    "                repidans=[workzone01[i].X for i in range(linksize)]\n",
    "            except:\n",
    "                workzonenum=np.inf\n",
    "                repidans=np.inf\n",
    "            return workzonenum, repidans\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculate Pareto frontier of each link.\n",
    "#   For each link, first randomly generate repair pattern,\n",
    "#   then calculate the optimal 1 day work zone schedule while decreasing the maximum number of continuous work zones per day\n",
    "def alllinksparato(cost_data,maxmachineperday=100,maxwznum=10,repprob=0.2,seedstart=0):\n",
    "    linksnum=len(cost_data)\n",
    "    alllinksparatocost=np.zeros((linksnum,maxmachineperday))\n",
    "    allrepid=[]\n",
    "    allworkzoneid=[[0 for i in range(maxmachineperday)] for j in range(linksnum)]\n",
    "    for linkid in range(linksnum):\n",
    "        linkrepid=random_rep_id(cost_data[linkid],repprob,seed=linkid+seedstart)\n",
    "        allrepid.append(linkrepid)\n",
    "        for machinenum in range(maxmachineperday):\n",
    "            try:\n",
    "                alllinksparatocost[linkid][machinenum], allworkzoneid[linkid][machinenum]=linkrepplans(linkrepid,machinecost=1000, workzonecost=100,maxworkzonelength=maxwznum,maxmachinenum=machinenum)\n",
    "            except:\n",
    "                alllinksparatocost[linkid][machinenum], allworkzoneid[linkid][machinenum]=np.inf,np.inf\n",
    "    return  alllinksparatocost, allrepid, allworkzoneid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of Pareto frontier of each link\n",
    "wzformn, allrepidmn, allworkzoneidmn=alllinksparato(cost_data_array,100,10,repprob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pareto frontiers into boardlist for the next step\n",
    "maxmachineperday=100\n",
    "boardlist=[]\n",
    "for linkid in range(len(cost_data_array)):\n",
    "    boardlinklist=[]\n",
    "    tmpwznm=1000000\n",
    "    for j in range(maxmachineperday):\n",
    "            if wzformn[linkid][j]<=100000 and wzformn[linkid][j]<tmpwznm:\n",
    "                boardlinklist.append([j,round(wzformn[linkid][j])])\n",
    "                tmpwznm=wzformn[linkid][j]\n",
    "    boardlist.append(boardlinklist)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Upper level: Link-unit network-level optimal work zone assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Gurobi Model for upper level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-04-10\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter MIPFocus to value 3\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i9-9980XE CPU @ 3.00GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 18 physical cores, 36 logical processors, using up to 18 threads\n",
      "\n",
      "Optimize a model with 13281 rows, 41041 columns and 122359 nonzeros\n",
      "Model fingerprint: 0xda366038\n",
      "Variable types: 40656 continuous, 385 integer (157 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+04]\n",
      "  Objective range  [2e+00, 3e+03]\n",
      "  Bounds range     [1e+00, 1e+03]\n",
      "  RHS range        [1e+00, 3e+04]\n",
      "Presolve removed 382 rows and 232 columns\n",
      "Presolve time: 0.02s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.03 seconds (0.03 work units)\n",
      "Thread count was 1 (of 36 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timerange=range(timespan)\n",
    "grbm=()\n",
    "grbm=grb.Model()\n",
    "x={}\n",
    "y={}\n",
    "FlowRsv={}\n",
    "Cap={}\n",
    "close={}\n",
    "CloseCons={}\n",
    "RepairOnce={}\n",
    "cost_origin_dict=dict(zip(links_data_tuple,cost_data_array))\n",
    "flowtype_list=range(len(odmat))\n",
    "links_data2_array=links_data_array#\n",
    "links_data2_tuple=links_data_tuple#\n",
    "cost_data_array2_array=cost_data_array\n",
    "capacity_data2_array=capacity_dict\n",
    "detour_tuple=()\n",
    "detour_list=[[0,0],]\n",
    "detour_cost_array=[]\n",
    "for f in flowtype_list:\n",
    "    detour_tuple=detour_tuple+list_to_tuple([[odmat[f][0],odmat[f][1]]])\n",
    "    detour_list=np.row_stack((detour_list, odmat[f][:2]))\n",
    "    detour_cost_array=np.append( detour_cost_array,3000)\n",
    "detour_list=np.delete(detour_list,0,0)\n",
    "detour_dict=dict(zip(detour_tuple,detour_cost_array))\n",
    "outflow_dict=dict(zip([(i,f) for (i,f) in product(nodes,flowtype_list)],np.zeros(len(nodes)*len(flowtype_list))))\n",
    "count=0\n",
    "for f in flowtype_list:\n",
    "    onode=odmat[f][0]\n",
    "    dnode=odmat[f][1]\n",
    "    flow=odmat[f][2]\n",
    "    outflow_dict[(onode,f)]=-flow\n",
    "    outflow_dict[(dnode,f)]=flow\n",
    "ynwlist=list(itertools.product(links_data_tuple,np.array(flowtype_list),np.array(timerange)))\n",
    "ydetourlist=list(itertools.product(detour_tuple,np.array(timerange)))\n",
    "ynw=grbm.addVars(ynwlist,lb=0)\n",
    "ydet=grbm.addVars(ydetourlist,lb=0)\n",
    "xlist=list(itertools.product(links_data_tuple,np.array(timerange)))\n",
    " \n",
    "\n",
    "x01num=grbm.addVars(xlist, vtype=\"B\")\n",
    "\n",
    "xnum=grbm.addVars(xlist, vtype=\"I\", lb=0,ub=max(maxmachinenum,100))\n",
    "\n",
    "xtlist=list(links_data_tuple)\n",
    "xtnum=grbm.addVars(xtlist, vtype=\"I\", lb=0,ub=max(maxmachinenum,100))\n",
    "\n",
    "wznum=grbm.addVars(xtlist, vtype=\"I\", lb=0,ub=max(maxmachinenum*10,1000))\n",
    "\n",
    "# Define detour routes on the network\n",
    "detour_indicator=dict(zip([(i,f) for (i,f) in product(nodes,flowtype_list)],np.zeros(len(nodes)*len(flowtype_list))))\n",
    "count=0\n",
    "for f in flowtype_list:\n",
    "    for i in nodes:\n",
    "        if detour_list[f][0]==i:\n",
    "            detour_indicator[(i,f)]=1\n",
    "        elif detour_list[f][1]==i:\n",
    "            detour_indicator[(i,f)]=-1\n",
    "\n",
    "#Decide od nodes for each traffic demands\n",
    "all_node_link_start_list=[]\n",
    "all_node_link_end_list=[]\n",
    "for n in nodes:\n",
    "    node_link_start_list=[]\n",
    "    node_link_end_list=[]\n",
    "    for (i,j) in links_data_array:\n",
    "        if i==n:\n",
    "            node_link_start_list.append([i,j])\n",
    "        elif j==n:\n",
    "            node_link_end_list.append([i,j])\n",
    "    all_node_link_start_list.append(list(node_link_start_list))\n",
    "    all_node_link_end_list.append(list(node_link_end_list))\n",
    "\n",
    "all_node_detour_start_list=[]\n",
    "all_node_detour_end_list=[]\n",
    "for n in nodes:\n",
    "    node_detour_start_list=[]\n",
    "    node_detour_end_list=[]\n",
    "    for (i,j) in detour_list:\n",
    "        if i==n:\n",
    "            node_detour_start_list.append([i,j])\n",
    "        elif j==n:\n",
    "            node_detour_end_list.append([i,j])\n",
    "    all_node_detour_start_list.append(list(node_detour_start_list))\n",
    "    all_node_detour_end_list.append(list(node_detour_end_list))\n",
    "\n",
    "#Constraints\n",
    "FlowRsv=grbm.addConstrs(grb.quicksum(ynw[(n,m),f,t]for (n,m) in all_node_link_start_list[i])\n",
    "+ydet[(detour_list[f][0],detour_list[f][1]),t]*detour_indicator[(i+1,f)] \n",
    "- grb.quicksum(ynw[(n,m),f,t]for (n,m) in all_node_link_end_list[i]) \n",
    "== -outflow_dict[nodes[i],f] for (f,i,t) in product(flowtype_list, range(len(nodes)),timerange))   \n",
    "x01consts=grbm.addConstrs(x01num[(i,j),t]*maxmachinenum>=xnum[(i,j),t] for ((i,j),t) in product(links_data_array,timerange))\n",
    "Cap=grbm.addConstrs(grb.quicksum(ynw[(i,j),f,t] for f in flowtype_list) <= capacity_dict[i,j]*(1-Brate*x01num[(i,j),t]) for ((i,j),t) in product(links_data_array,timerange))\n",
    "Xnumconst=grbm.addConstrs(xtnum[i,j]==grb.quicksum(xnum[(i,j),t] for t in timerange)for(i,j) in links_data_array  )\n",
    "mnumconst=grbm.addConstrs(grb.quicksum(xnum[(i,j),t] for (i,j) in links_data_array)<=maxmachinenum for t in timerange )\n",
    "\n",
    "#Add Pareto frontier into the upper level problem\n",
    "xtnumind={}\n",
    "for i in range(len(cost_data_array )):\n",
    "    (m,n)=links_data_tuple[i]\n",
    "    grbm.addConstr(xtnum[m,n]>=boardlist[i][0][0])\n",
    "    grbm.addConstr(xtnum[m,n]<=boardlist[i][-1][0])\n",
    "    xtnumind[i]=grbm.addVars(len(boardlist[i]), vtype=\"B\")\n",
    "    grbm.addConstr(grb.quicksum(xtnumind[i][j] for j in range(len(boardlist[i])))==1)\n",
    "    grbm.addConstr(grb.quicksum(xtnumind[i][j]*boardlist[i][j][1] for j in range(len(boardlist[i])))==wznum[m,n])\n",
    "    grbm.addConstr(grb.quicksum(xtnumind[i][j]*boardlist[i][j][0] for j in range(len(boardlist[i])))==xtnum[m,n])\n",
    "    \n",
    "#Set of objective function\n",
    "grbm.setObjective(\n",
    "ucrate*grb.quicksum(cost_origin_dict[n,m]*ynw[(n,m),f,t] for((n,m),f,t) in product(links_data_array,flowtype_list,timerange))\n",
    "+ucrate*grb.quicksum(detour_dict[n,m]*ydet[(n,m),t] for((n,m),t) in product(detour_list,timerange))\n",
    "+wcrate*grb.quicksum(xtnum[n,m]*mcucost\n",
    "+wznum[n,m]*wzucost  \n",
    "for (n,m) in links_data_array)\n",
    ")    \n",
    "\n",
    "grbm.update()\n",
    "grbm.setParam('MIPGAP',0.01)\n",
    "grbm.setParam('MIPfocus',3)\n",
    "grbm.optimize()\n",
    "grbm.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: The number of workzone each day on each link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Unable to retrieve attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxtnum\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlinks_data_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(\u001b[43mxtnum\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (n,m) \u001b[38;5;129;01min\u001b[39;00m links_data_array)\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\var.pxi:125\u001b[0m, in \u001b[0;36mgurobipy.Var.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\var.pxi:153\u001b[0m, in \u001b[0;36mgurobipy.Var.getAttr\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\attrutil.pxi:103\u001b[0m, in \u001b[0;36mgurobipy._getattr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Unable to retrieve attribute 'X'"
     ]
    }
   ],
   "source": [
    "otptx={(i,j,t):xnum[(i,j),t].X for ((i,j),t) in product(links_data_array,timerange)}\n",
    "print(otptx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
